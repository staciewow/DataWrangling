{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using csv Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "DATADIR = \"\"\n",
    "DATAFILE = \"745090.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(csv):\n",
    "    with open(csv, 'rb') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(datafile,'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        name = next(reader)[1]\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "        \n",
    "    # Do not change the line below\n",
    "    return (name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOUNTAIN VIEW MOFFETT FLD NAS\n",
      "['01/01/2005', '03:00', '0', '0', '0', '2', '0', '0', '2', '0', '0', '2', '0', '0', '2', '0', '0', '2', '0', '0', '2', '0', '0', '2', '0', '8', 'E', '9', '8', 'E', '9', '7.0', 'A', '7', '6.0', 'A', '7', '93', 'A', '7', '1013', 'A', '7', '120', 'A', '7', '2.1', 'A', '7', '16100', 'A', '7', '2100', 'A', '7', '1.1', 'E', '8', '0.099', 'F', '8', '0.160', 'F', '8', '0', '1', 'A', '7']\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    datafile = os.path.join(DATADIR, DATAFILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\"\n",
    "\n",
    "    print (name)\n",
    "    print (data[2])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "from zipfile import ZipFile\n",
    "\n",
    "datafile = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "outfile = \"2013_Max_Loads.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_zip(datafile):\n",
    "    with ZipFile('{0}.zip'.format(datafile), 'r') as myzip:\n",
    "        myzip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "    data = []\n",
    "    \n",
    "    maxvalues = {} # structure: {label: [maxload(0), time(1)]}\n",
    "    for col in range(1, sheet.ncols - 1):\n",
    "        label = sheet.cell_value(0, col)\n",
    "        column = sheet.col_values(col, start_rowx=1, end_rowx=sheet.nrows)\n",
    "        maxvalues[label] = [max(column)]\n",
    "        maxrownum = column.index(max(column)) + 1\n",
    "        maxvalues[label].append(sheet.cell_value(maxrownum, 0))\n",
    "    \n",
    "    stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH', 'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    for station in stations:\n",
    "        row = [station]\n",
    "        time = xlrd.xldate_as_tuple(maxvalues[station][1], 0)\n",
    "        for index in range(len(time[:4])):\n",
    "            row.append(time[index])\n",
    "        row.append(maxvalues[station][0])\n",
    "        data.append(row)\n",
    "\n",
    "    print (data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(data, filename):\n",
    "    with open(filename, 'w') as csvfile:\n",
    "        datawriter = csv.writer(csvfile, delimiter = '|')\n",
    "        datawriter.writerow(['Station', 'Year', 'Month', 'Day', 'Hour', 'Max Load'])\n",
    "        datawriter.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['COAST', 2013, 8, 13, 17, 18779.025510000003], ['EAST', 2013, 8, 5, 17, 2380.1654089999956], ['FAR_WEST', 2013, 6, 26, 17, 2281.2722140000024], ['NORTH', 2013, 8, 7, 17, 1544.7707140000005], ['NORTH_C', 2013, 8, 7, 18, 24415.570226999993], ['SOUTHERN', 2013, 8, 8, 16, 5494.157645], ['SOUTH_C', 2013, 8, 8, 18, 11433.30491600001], ['WEST', 2013, 8, 7, 17, 1862.6137649999998]]\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    #open_zip(datafile)\n",
    "    data = parse_file(datafile)\n",
    "    save_file(data, outfile)\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': \"2281.2722140000024\", 'Year': \"2013\", \"Month\": \"6\", \"Day\": \"26\", \"Hour\": \"17\"}}\n",
    "    \n",
    "    fields = [\"Year\", \"Month\", \"Day\", \"Hour\", \"Max Load\"]\n",
    "    with open(outfile) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "            s = line[\"Station\"]\n",
    "            if s == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    assert ans[s][field] == line[field]\n",
    "\n",
    "        \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import requests\n",
    "\n",
    "URL_MAIN = \"http://api.nytimes.com/svc/\"\n",
    "URL_POPULAR = URL_MAIN + \"mostpopular/v2/\"\n",
    "API_KEY = { \"popular\": \"\",\n",
    "            \"article\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_from_file(kind, period):\n",
    "    filename = \"popular-{0}-{1}.json\".format(kind, period)\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    titles = []\n",
    "    urls =[]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # create titles\n",
    "    for dic in data:\n",
    "        asset = {}\n",
    "        key = dic['section']\n",
    "        val = dic['title']\n",
    "        asset[key] = val\n",
    "        titles.append(asset)\n",
    "\n",
    "    # create urls\n",
    "    # { 'media': [ { 'm-m': [{},{},{}] } , { 'm-m':[{},{},{}] } ] ... }\n",
    "    for dic in data:\n",
    "        for item in dic['media']:\n",
    "            for media in item['media-metadata']:\n",
    "                if media['format'] == 'Standard Thumbnail':\n",
    "                    urls.append(media['url'])\n",
    "\n",
    "    return (titles, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_site(url, target, offset):\n",
    "    # This will set up the query with the API key and offset\n",
    "    # Web services often use offset paramter to return data in small chunks\n",
    "    # NYTimes returns 20 articles per request, if you want the next 20\n",
    "    # You have to provide the offset parameter\n",
    "    if API_KEY[\"popular\"] == \"\" or API_KEY[\"article\"] == \"\":\n",
    "        print (\"You need to register for NYTimes Developer account to run this program.\")\n",
    "        print (\"See Intructor notes for information\")\n",
    "        return False\n",
    "    params = {\"api-key\": API_KEY[target], \"offset\": offset}\n",
    "    r = requests.get(url, params = params)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular(url, kind, days, section=\"all-sections\", offset=0):\n",
    "    # This function will construct the query according to the requirements of the site\n",
    "    # and return the data, or print an error message if called incorrectly\n",
    "    if days not in [1,7,30]:\n",
    "        print (\"Time period can be 1,7, 30 days only\")\n",
    "        return False\n",
    "    if kind not in [\"viewed\", \"shared\", \"emailed\"]:\n",
    "        print (\"kind can be only one of viewed/shared/emailed\")\n",
    "        return False\n",
    "\n",
    "    url = URL_POPULAR + \"most{0}/{1}/{2}.json\".format(kind, section, days)\n",
    "    data = query_site(url, \"popular\", offset)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(kind, period):\n",
    "    # This will process all results, by calling the API repeatedly with supplied offset value,\n",
    "    # combine the data and then write all results in a file.\n",
    "    data = get_popular(URL_POPULAR, \"viewed\", 1)\n",
    "    num_results = data[\"num_results\"]\n",
    "    full_data = []\n",
    "    with codecs.open(\"popular-{0}-{1}-full.json\".format(kind, period), encoding='utf-8', mode='w') as v:\n",
    "        for offset in range(0, num_results, 20):        \n",
    "            data = get_popular(URL_POPULAR, kind, period, offset=offset)\n",
    "            full_data += data[\"results\"]\n",
    "        \n",
    "        v.write(json.dumps(full_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    titles, urls = article_overview(\"viewed\", 1)\n",
    "    assert len(titles) == 20\n",
    "    assert len(urls) == 30\n",
    "    assert titles[2] == {'Opinion': 'Professors, We Need You!'}\n",
    "    assert urls[20] == 'http://graphics8.nytimes.com/images/2014/02/17/sports/ICEDANCE/ICEDANCE-thumbStandard.jpg'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    titles = []\n",
    "    urls =[]\n",
    "\n",
    "    for article in data:\n",
    "        section = article[\"section\"]\n",
    "        title = article[\"title\"]\n",
    "        titles.append({section: title})\n",
    "        if \"media\" in article:\n",
    "            for m in article[\"media\"]:\n",
    "                for mm in m[\"media-metadata\"]:\n",
    "                    if mm[\"format\"] == \"Standard Thumbnail\":\n",
    "                        urls.append(mm[\"url\"])\n",
    "    return (titles, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
