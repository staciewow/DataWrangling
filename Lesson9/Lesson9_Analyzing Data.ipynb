{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who Tweeted Most?\n",
    "\n",
    "1. Group tweets by user\n",
    "2. Count each user's tweets\n",
    "3. Sort into descentding order\n",
    "4. Select user at top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5b101612a24d683bec191b47'),\n",
      " 'contributors': None,\n",
      " 'coordinates': None,\n",
      " 'created_at': 'Thu Sep 02 18:11:23 +0000 2010',\n",
      " 'entities': {'hashtags': [], 'urls': [], 'user_mentions': []},\n",
      " 'favorited': False,\n",
      " 'geo': None,\n",
      " 'id': 22819396900,\n",
      " 'in_reply_to_screen_name': None,\n",
      " 'in_reply_to_status_id': None,\n",
      " 'in_reply_to_user_id': None,\n",
      " 'place': None,\n",
      " 'retweet_count': None,\n",
      " 'retweeted': False,\n",
      " 'source': 'web',\n",
      " 'text': 'eu preciso de terminar de fazer a minha tabela, está muito foda **',\n",
      " 'truncated': False,\n",
      " 'user': {'contributors_enabled': False,\n",
      "          'created_at': 'Fri Jul 03 21:44:05 +0000 2009',\n",
      "          'description': 'só os loucos sabem (:',\n",
      "          'favourites_count': 1,\n",
      "          'follow_request_sent': None,\n",
      "          'followers_count': 102,\n",
      "          'following': None,\n",
      "          'friends_count': 73,\n",
      "          'geo_enabled': False,\n",
      "          'id': 53507833,\n",
      "          'lang': 'en',\n",
      "          'listed_count': 0,\n",
      "          'location': '',\n",
      "          'name': 'Beatriz Helena Cunha',\n",
      "          'notifications': None,\n",
      "          'profile_background_color': '081114',\n",
      "          'profile_background_image_url': 'http://a1.twimg.com/profile_background_images/133178546/biatwitter.jpg',\n",
      "          'profile_background_tile': True,\n",
      "          'profile_image_url': 'http://a2.twimg.com/profile_images/1036412454/OgAAADXK9q6kaxrvfwQTINH66RVLAH9YHb-veRTA4FaWb9KtbGGV_yKTGzmvzTfJidqAb5gK_mpspIE-MIvAASGH2CwAm1T1UIPQk0-HS8x_TV5kdnW30nch7ODk-1_normal.jpg',\n",
      "          'profile_link_color': 'eb55b6',\n",
      "          'profile_sidebar_border_color': '1c9dbd',\n",
      "          'profile_sidebar_fill_color': '768575',\n",
      "          'profile_text_color': '25b8c2',\n",
      "          'profile_use_background_image': True,\n",
      "          'protected': False,\n",
      "          'screen_name': 'Bia_cunha1',\n",
      "          'show_all_inline_media': False,\n",
      "          'statuses_count': 3504,\n",
      "          'time_zone': 'Brasilia',\n",
      "          'url': 'http://http://www.orkut.com.br/Main#Profile?uid=1433295880233078770',\n",
      "          'utc_offset': -10800,\n",
      "          'verified': False}}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import pprint\n",
    "\n",
    "def insert_data(data, db):\n",
    "    for a in data:\n",
    "        db.twitter.insert(a)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client.examples\n",
    "    \n",
    "    # Available here: http://content.udacity-data.com/ud032/twitter/twitter.json.zip\n",
    "    with open('twitter.json', 'r') as f:\n",
    "        ## json.loads() takes a string, while json.load() takes a file-like object.\n",
    "        ## http://stackoverflow.com/questions/11568246/loading-several-text-files-into-mongodb-using-pymongo\n",
    "        for tweet in f.readlines():\n",
    "            db.twitter.insert(json.loads(tweet))\n",
    "    pprint.pprint(db.twitter.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$$group,  $sort  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client[db_name]\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    pipeline = [{\"$group\": {\"_id\": \"$source\",\n",
    "                            \"count\": {\"$sum\": 1}}},\n",
    "                 {\"$sort\": {\"count\": -1}},\n",
    "                 {\"$limit\" : 5 }]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sources(db, pipeline):\n",
    "    result = db.tweets.aggregate(pipeline)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.command_cursor.CommandCursor object at 0x1034c55f8>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    db = get_db('example_tweets')\n",
    "    pipeline = make_pipeline()\n",
    "    result = tweet_sources(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$$project,  $match,  $skip,  $limit,  $unwind  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who has the highest follower/friends ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highest_ratio():\n",
    "    result = db.tweets.aggregate([\n",
    "        {\"$match\": {\"user.friends_count\": {\"$gt\": 0},\n",
    "                   \"user.follower_count\": {\"$gt\": 0}}},\n",
    "        {\"$project\": {\"ratio\":{\"$divide\": [\"$user.followers_count\",\n",
    "                                          \"$user.friends_count\"]},\n",
    "                     \"screen_name\": \"$user.screen_name\"}},\n",
    "        {\"$sort\": {\"ratio\": -1}},\n",
    "        {\"$limit\": 1}\n",
    "    ])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use $project to:\n",
    "- Include fields from the original document\n",
    "- Insert computed fields\n",
    "- Rename fields\n",
    "- Create fields that hold sub-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [ \n",
    "        {\"$match\": {\"user.time_zone\": \"Brasilia\",\n",
    "                   \"user.statuses_count\": {\"$gte\": 100}}},\n",
    "        {\"$project\": {\"followers\": \"$user.followers_count\",\n",
    "                      \"screen_name\": \"$user.screen_name\",\n",
    "                      \"tweets\": \"$user.statuses_count\"}},\n",
    "        {\"$sort\": {\"followers\": -1}},\n",
    "        {\"$limit\": 1}         \n",
    "        ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use $project?\n",
    "\n",
    "#### For example, to answer the question \"Who included the most user mentions?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_mentions():\n",
    "    result = db.tweets.aggregate([\n",
    "        {\"$unwind\": \"$entities.user_mentions\"},\n",
    "        {\"$group\": {\"_id\": \"$user.screen_name\",\n",
    "                   \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 1}\n",
    "    ])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.command_cursor.CommandCursor object at 0x10356d940>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    result = user_mentions()\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Another example\n",
    "#For this exercise, let's return to our cities infobox dataset. The question we would like you to answer\n",
    "#is as follows:  Which region or district in India contains the most cities? (Make sure that the count of\n",
    "#cities is stored in a field named 'count'; see the assertions at the end of the script.)\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{\"$unwind\": \"$isPartOf\"},\n",
    "                {\"$match\": {\"country\": \"India\"}},\n",
    "                {\"$group\": {\"_id\": \"$isPartOf\",\n",
    "                            \"count\": {\"$sum\": 1}}},\n",
    "                {\"$sort\": {\"count\": -1}}\n",
    "                ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $group operation:\n",
    "\n",
    "- $sum\n",
    "\n",
    "- $first\n",
    "\n",
    "- $last\n",
    "\n",
    "- $max\n",
    "\n",
    "- $min\n",
    "\n",
    "- $avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashtag_retweet_avg():\n",
    "    result = db.tweets.aggregate([\n",
    "        {\"$unwind\": \"$entities.hastags\"},\n",
    "        {\"$group\": {\"_id\": \"$entities.hastags.text\",\n",
    "                   \"retweet_avg\": {\"$avg\": \"$retweet_count\"}}},\n",
    "        {\"$sort\": {\"retweet_avg\": -1}}\n",
    "    ])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays: \n",
    "\n",
    "- $push \n",
    "\n",
    "- $addToSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashtag_retweet_avg():\n",
    "    result = db.tweets.aggregate([\n",
    "        {\"$unwind\": \"$entities.hastags\"},\n",
    "        {\"$group\": {\"_id\": \"$entities.hastags.text\",\n",
    "                   \"unique_hashtags\": {\n",
    "                       \"$addToSet\": \"$$entities.hashtags.text\"}}},\n",
    "        {\"$sort\": {\"_id\": -1}}\n",
    "    ])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$group\": {\"_id\": \"$user.screen_name\",\n",
    "                    \"tweet_texts\": {\"$push\": \"$text\"},\n",
    "                    \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 5}\n",
    "        ]\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who has mentioned the most unique users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_user_mentions():\n",
    "    result = db.tweets.aggregate([\n",
    "        {\"$unwind\": \"$entities.user_mentions\"},\n",
    "        {\"$group\": {\n",
    "            \"_id\": \"$user.screen_name\",\n",
    "            \"mset\": {\n",
    "                \"$addToSet\": \"$entities.user_mentions.screen_name\"\n",
    "            }\n",
    "        }},\n",
    "        {\"$unwind\": \"$mset\"},\n",
    "        {\"$group\": {\"_id\": \"$_id\",\n",
    "                   \"count\": {\"$sum\": 1}}},\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 10}\n",
    "    ])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Another example:\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{\"$match\": {\"country\": \"India\"}},\n",
    "                # First, match India as the country of interest; data contains world data.\n",
    "                {\"$unwind\": \"$isPartOf\"},\n",
    "                # Unwind regions; some cities belong to multiple regions.\n",
    "                {\"$group\": {\"_id\": \"$isPartOf\",\n",
    "                            # Now group on each region.\n",
    "                            \"totPop\": {\"$sum\": \"$population\"},\n",
    "                            # Sum up the population of all of the cities for each region.\n",
    "                            \"count\": {\"$sum\": 1},\n",
    "                            # Count the number of times each region shows up.\n",
    "                 \"average\": {\"$avg\": \"$population\"}}},\n",
    "                # Create an average for each region.\n",
    "                {\"$group\": {\"_id\": \"India Regional City Population Average\",\n",
    "                # Now group by a constant to group everything together.\n",
    "                 \"avg\": {\"$avg\": \"$average\"}}}]\n",
    "                # And finally, get an average of the average region populations.\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
